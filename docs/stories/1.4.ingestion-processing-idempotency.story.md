# Story 1.4: Ingestion Processing & Idempotency

## Status
Done

## Story
**As a** System Operator,
**I want** metrics to be processed asynchronously and deduplicated,
**so that** the API remains fast and data remains consistent despite network retries.

## Acceptance Criteria
1. Ingested metrics are dispatched to a Redis-backed Laravel Job.
2. Job worker persists metrics to the `metrics_raw` table in MariaDB.
3. The system uses a `dedupe_id` (if provided in payload) to prevent duplicate entries for the same event.
4. Failed jobs are automatically retried with exponential backoff.

## Tasks / Subtasks
- [x] Task 1: Database Migration for Metrics (AC: 2, 3)
    - [x] Create migration for `metrics_raw` table.
    - [x] Columns: `id` (BIGINT PK), `tenant_id` (BINARY(16)), `agent_id` (VARCHAR(64)), `metric_name` (VARCHAR(64)), `value` (DOUBLE(16,4)), `timestamp` (TIMESTAMP(6)), `dedupe_id` (VARCHAR(128) UNIQUE). [Source: architecture/7-database-schema.md]
    - [x] Add index `idx_tenant_metric_time` on (`tenant_id`, `metric_name`, `timestamp` DESC). [Source: architecture/7-database-schema.md]
- [x] Task 2: Metric Model & Repository (AC: 2, 3)
    - [x] Create `App\Models\Metric` model.
    - [x] Configure `$fillable` for all fields.
    - [x] Ensure `timestamp` is cast correctly for high-precision.
- [x] Task 3: Job Implementation - `ProcessMetricSubmission` (AC: 1, 2, 3, 4)
    - [x] Update `App\Jobs\ProcessMetricSubmission` to implement `ShouldQueue`.
    - [x] Configure `public $tries = 5;` and `public $backoff = [10, 30, 60];`. [Source: Epic 1.4 AC 4]
    - [x] Implement `handle()` logic:
        - Use database transaction for atomicity.
        - Iterate through the metrics array.
        - Use `upsert` or `firstOrCreate` with `dedupe_id` if present. [Source: architecture/4-data-models.md]
        - If `dedupe_id` is null, always insert.
        - Associate with `tenant_id` from the job context.
- [x] Task 4: Integration Testing (AC: 1, 2, 3, 4)
    - [x] Create `tests/Feature/MetricProcessingTest.php`.
    - [x] Test cases:
        - [x] Verify single metric persistence to `metrics_raw`.
        - [x] Verify bulk metric persistence (multi-row insert).
        - [x] Verify idempotency: pushing same `dedupe_id` twice results in only one DB record.
        - [x] Verify job retries on DB failure (can use `Queue::fake()` or mock DB).
        - [x] Verify `tenant_id` is correctly stored in binary format.

## Dev Notes
- **Previous Story Insights:**
    - `ProcessMetricSubmission` job already exists as a placeholder and is dispatched by `MetricIngestionController`.
    - The payload is already normalized to an array in the controller.
    - Max bulk size is 1000 items, so `upsert` is safe and efficient.
- **Data Models:**
    - `metrics_raw` uses `BINARY(16)` for `tenant_id`. Ensure the `Metric` model handles UUID to Binary conversion (or use a trait if existing). [Source: architecture/7-database-schema.md]
    - `dedupe_id` is unique. Use `INSERT IGNORE` or Laravel's `upsert` to handle collisions gracefully. [Source: architecture/4-data-models.md]
- **File Locations:**
    - Migration: `database/migrations/YYYY_MM_DD_HHMMSS_create_metrics_raw_table.php`
    - Model: `app/Models/Metric.php`
    - Job: `app/Jobs/ProcessMetricSubmission.php`
    - Test: `tests/Feature/MetricProcessingTest.php`
- **Testing Requirements:**
    - Use `RefreshDatabase` trait.
    - Ensure `dedupe_id` logic is tested thoroughly.
    - Test that `timestamp` precision is maintained.

### Testing
- **Test File Location:** `tests/Feature/MetricProcessingTest.php`
- **Test Standards:** Laravel Pest/PHPUnit.
- **Frameworks:** PHPUnit, Laravel Testing utilities.
- **Specific Requirements:**
    - Must verify data in `metrics_raw` after job execution.
    - Must verify that `dedupe_id` prevents duplicate records.

## Change Log
| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2026-01-18 | 1.0 | Initial Story Draft | Bob (Scrum Master) |
| 2026-01-18 | 1.1 | Implementation Complete - All tasks finished, tests passing | James (Developer) |

## Dev Agent Record
### Agent Model Used
Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References
N/A - No blocking issues encountered

### Completion Notes List
- Successfully implemented metrics_raw table migration with all required columns and indexes
- Created Metric model with proper fillable fields and timestamp casting for high precision
- Updated ProcessMetricSubmission job with retry logic (5 tries, exponential backoff) and database persistence
- Implemented idempotency using dedupe_id with updateOrCreate logic
- Created comprehensive test suite with 9 test cases covering all acceptance criteria
- Fixed test database configuration by adding dedicated testing connection
- All 28 tests pass (90 assertions)
- Code passes Laravel Pint linting standards

### File List
**Created:**
- app/database/migrations/2026_01_17_222120_create_metrics_raw_table.php
- app/app/Models/Metric.php
- app/tests/Feature/MetricProcessingTest.php
- app/.env.testing

**Modified:**
- app/app/Jobs/ProcessMetricSubmission.php
- app/phpunit.xml
- app/config/database.php

## QA Results

### Review Date: 2026-01-18

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

The implementation is solid and follows Laravel best practices for job processing and database persistence. The use of high-precision timestamps and binary UUIDs aligns with the architecture specifications. 

During the review, a critical data isolation bug was identified where `dedupe_id` was globally unique, causing potential collisions across different tenants. This has been refactored to be unique per tenant. Additionally, the job processing was optimized from individual database calls to bulk `upsert` operations.

### Refactoring Performed

- **File**: `database/migrations/2026_01_17_222120_create_metrics_raw_table.php`
  - **Change**: Changed `dedupe_id` uniqueness from global to composite with `tenant_id`.
  - **Why**: Prevent cross-tenant data collisions where one tenant's metric might be dropped as a "duplicate" of another tenant's metric.
  - **How**: Replaced `unique()` on column with `$table->unique(['tenant_id', 'dedupe_id'])`.

- **File**: `app/Jobs/ProcessMetricSubmission.php`
  - **Change**: Refactored `handle()` to use bulk `upsert` and `insert`.
  - **Why**: Performance optimization and fixing the multi-tenancy deduplication isolation.
  - **How**: Grouped metrics by dedupe status and used `Metric::upsert()` for batch processing instead of a loop with `updateOrCreate()`.

- **File**: `tests/Feature/MetricProcessingTest.php`
  - **Change**: Added `test_dedupe_id_is_isolated_per_tenant`.
  - **Why**: Ensure regression testing for multi-tenant data isolation.

### Compliance Check

- Coding Standards: [✓]
- Project Structure: [✓]
- Testing Strategy: [✓]
- All ACs Met: [✓]

### Improvements Checklist

- [x] Refactored migration for tenant-scoped uniqueness
- [x] Optimized job to use bulk upsert (Performance improvement)
- [x] Added cross-tenant isolation test case

### Security Review

Tenant isolation for deduplication has been strictly enforced at both the database level (unique constraint) and application level (upsert keys). This prevents potential data injection/overwriting between tenants via manipulated `dedupe_id`s.

### Performance Considerations

Bulk processing (up to 1000 items per job) is now handled via a single `upsert` or `insert` query instead of N individual queries, significantly reducing database roundtrips and transaction overhead.

### Files Modified During Review

- `database/migrations/2026_01_17_222120_create_metrics_raw_table.php`
- `app/Jobs/ProcessMetricSubmission.php`
- `tests/Feature/MetricProcessingTest.php`

### Gate Status

Gate: PASS → docs/qa/gates/1.4-ingestion-processing-idempotency.yml
Risk profile: docs/qa/assessments/1.4-risk-20260118.md
Test design: docs/qa/assessments/1.4-test-design-20260118.md

### Recommended Status

[✓ Ready for Done]

