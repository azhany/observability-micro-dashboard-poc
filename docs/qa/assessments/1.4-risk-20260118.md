# Risk Profile: Story 1.4.ingestion-processing-idempotency

Date: 2026-01-18
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 5
- Critical Risks: 0
- High Risks: 1
- Risk Score: 81/100

The primary concern is the global uniqueness of the `dedupe_id`. As currently specified in the migration (`VARCHAR(128) UNIQUE`), a collision between two different tenants would cause data loss for one of them. This should be scoped per tenant.

## High Risks Requiring Attention

### 1. DATA-001: Global Uniqueness of `dedupe_id` Across Tenants

**Score: 6 (High)**
**Probability**: Medium - Agents might use common patterns or simple counters for `dedupe_id`. In a multi-tenant environment, the chance of collision across the entire database is non-negligible.
**Impact**: High - If Tenant A uses ID "123" and Tenant B also uses "123", Tenant B's metric will be dropped as a "duplicate", leading to silent data loss for Tenant B.
**Mitigation**:
- Change the unique constraint to be a composite index: `UNIQUE(tenant_id, dedupe_id)`.
- Ensure `dedupe_id` is always handled alongside `tenant_id` in the `upsert` logic.
**Testing Focus**: Idempotency test cases must include a scenario where two different tenants use the same `dedupe_id` and both records are successfully persisted.

## Risk Distribution

### By Category

- Data: 2 risks (1 high)
- Performance: 1 risk (0 high)
- Technical: 1 risk (0 high)
- Operational: 1 risk (0 high)
- Security: 0 risks (0 high) - *Note: Binary conversion has security implications but is categorized under TECH here.*

### By Component

- Frontend: 0 risks
- Backend: 2 risks
- Database: 3 risks
- Infrastructure: 0 risks

## Detailed Risk Register

| Risk ID  | Description                                      | Probability | Impact     | Score | Priority |
| -------- | ------------------------------------------------ | ----------- | ---------- | ----- | -------- |
| DATA-001 | Global `dedupe_id` collision across tenants      | Medium (2)  | High (3)   | 6     | High     |
| PERF-001 | DB lock contention on high-concurrency upserts   | Medium (2)  | Medium (2) | 4     | Medium   |
| TECH-001 | Binary UUID conversion errors (tenant_id)        | Low (1)     | High (3)   | 3     | Low      |
| OPS-001  | Redis queue backlog during DB downtime           | Low (1)     | Medium (2) | 2     | Low      |
| DATA-002 | Microsecond precision loss in timestamp(6)       | Low (1)     | Low (1)    | 1     | Minimal  |

## Risk-Based Testing Strategy

### Priority 1: High Risk Tests (DATA-001)
- **Multi-tenant Idempotency**: Verify that `dedupe_id` uniqueness is enforced *only* within the same tenant.
- **Payload Validation**: Ensure `dedupe_id` is not empty if provided, and handle nulls correctly.

### Priority 2: Medium Risk Tests (PERF-001)
- **Load Testing**: Simulate 10+ concurrent workers performing bulk upserts of 1000 items to check for deadlocks or significant latency spikes.
- **Transaction Atomicity**: Ensure that if one item in a bulk upsert fails, the entire batch is handled correctly (atomically).

### Priority 3: Low Risk Tests
- **Binary Format Integrity**: Query the `metrics_raw` table directly via SQL to verify `tenant_id` is stored in the correct 16-byte binary format and matches the original UUID.
- **Retry Logic**: Mock a database connection failure and verify the job is released back to the queue with the expected delay.

## Risk Acceptance Criteria

### Must Fix Before Production
- All High risks (DATA-001). The unique constraint must be scoped to `tenant_id`.

### Can Deploy with Mitigation
- PERF-001: Monitor MariaDB `Slow_queries` and `Innodb_row_lock_time`.
- OPS-001: Ensure Redis has sufficient memory and eviction policy is set to `noeviction` for queue use.

## Monitoring Requirements
- **Queue Depth**: Alert if `ProcessMetricSubmission` queue exceeds 10,000 items.
- **DB Write Latency**: Monitor `upsert` execution time.
- **Failed Jobs**: Alert on `failed_jobs` table entries.

## Risk Review Triggers
- Modification of the database schema.
- Change in the bulk ingestion size (currently 1000).
- Introduction of new agents with different `dedupe_id` generation strategies.
